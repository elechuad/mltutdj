{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE2211 Tutorial 6\n",
    "\n",
    "### by Chua Dingjuan (Sept 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 Python Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from numpy.linalg import inv \n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6(a) Split the database into two sets: 74% of samples for training, and 26% of samples for testing. Hint: you might want to utilize from sklearn.model_selection import train_test_split for the splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111,)\n",
      "(39,)\n",
      "y_test is : \n",
      " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "## (a) split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "iris_dataset['data'], iris_dataset['target'], test_size=0.26, random_state=0)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print('y_test is : \\n', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6(b) Construct the target output using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yts_onehot is : \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## (b) one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder=OneHotEncoder(sparse=False)          #sparse=False is used so that we don't have to use .toarray() later\n",
    "reshaped = y_train.reshape(len(y_train), 1)         #converts y_train into a column vector\n",
    "Ytr_onehot = onehot_encoder.fit_transform(reshaped) #one-hot encoding!\n",
    "#print('Ytr_onehot is : \\n', Ytr_onehot)\n",
    "\n",
    "reshaped = y_test.reshape(len(y_test), 1)           #converts y_test into a column vector\n",
    "Yts_onehot = onehot_encoder.fit_transform(reshaped) #one-hot encoding!\n",
    "print('Yts_onehot is : \\n', Yts_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6(c) Perform a linear regression for classification (without inclusion of ridge, utilizing one-hot encoding for the learning target) and compute the number of test samples that are classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11529555  0.20404125 -0.15416052]\n",
      " [ 0.21791487 -0.29396894  0.14549901]\n",
      " [-0.25363127  0.18246449  0.0362187 ]\n",
      " [-0.04023153 -0.58240246  0.57367321]]\n",
      "[[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "## (c) Linear Classification\n",
    "w = inv(X_train.T @ X_train) @ X_train.T @ Ytr_onehot\n",
    "print(w)\n",
    "\n",
    "yt_est = X_test.dot(w);\n",
    "yt_cls = [[1 if y == max(x) else 0 for y in x] for x in yt_est ]\n",
    "print(yt_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "0.717948717948718\n"
     ]
    }
   ],
   "source": [
    "m1 = np.matrix(Yts_onehot)      #np.matrix here is optional\n",
    "m2 = np.matrix(yt_cls)\n",
    "difference = np.abs(m1 - m2)\n",
    "\n",
    "#print(difference)\n",
    "\n",
    "correct = np.where(~difference.any(axis=1))[0]\n",
    "accuracy = len(correct)/len(difference)\n",
    "\n",
    "print(len(correct))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "## (d) Polynomial Classification\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "P = poly.fit_transform(X_train)\n",
    "Pt = poly.fit_transform(X_test)\n",
    "if P.shape[0] > P.shape[1]:\n",
    " wp = inv(P.T @ P) @ P.T @ Ytr_onehot\n",
    "else:\n",
    " wp = P.T @ inv(P @ P.T) @ Ytr_onehot\n",
    "#print(wp)\n",
    "\n",
    "yt_est_p = Pt.dot(wp);\n",
    "yt_cls_p = [[1 if y == max(x) else 0 for y in x] for x in yt_est_p ]\n",
    "#print(yt_cls_p)\n",
    "\n",
    "m1 = np.matrix(Yts_onehot)\n",
    "m2 = np.matrix(yt_cls_p)\n",
    "difference = np.abs(m1 - m2)\n",
    "#print(difference)\n",
    "\n",
    "correct_p = np.where(~difference.any(axis=1))[0]\n",
    "accuracy_p = len(correct_p)/len(difference)\n",
    "print(len(correct_p))\n",
    "print(accuracy_p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
