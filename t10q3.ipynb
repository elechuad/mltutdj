{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE2211 Tutorial 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @author: KAToh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 Python Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spambase.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m## Get training and test sets   \u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m (X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m (X_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn [1], line 16\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(Train)\u001b[0m\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## Read the training data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspambase.data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mnext\u001b[39m(reader, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spambase.data'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Feb 18 17:08:04 2020\n",
    "@author: KAToh\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## load data set\n",
    "def load_data(Train=False):\n",
    "    import csv\n",
    "    data = []\n",
    "    ## Read the training data\n",
    "    f = open('spambase.data')\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "    f.close()\n",
    "    ## x[:-1]: omit the last element of each x row\n",
    "    X = np.array([x[:-1] for x in data]).astype(np.float)\n",
    "    ## x[-1]: the first element from the right instead of from the left \n",
    "    y = np.array([x[-1] for x in data]).astype(np.float)\n",
    "    del data # free up the memory\n",
    "    if Train:\n",
    "        # returns X_train, X_test, y_train, y_test\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=8)\n",
    "    else:\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "## Get training and test sets   \n",
    "X_train, X_test, y_train, y_test = load_data(Train=True)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train)\n",
    "\n",
    "## Linear regression\n",
    "inv_XTX = np.linalg.inv(X_train.transpose().dot(X_train))\n",
    "pinv = inv_XTX.dot(X_train.transpose())\n",
    "W = pinv.dot(y_train)\n",
    "## Prediction\n",
    "y_predict = X_test.dot(W)\n",
    "\n",
    "print(y_predict)\n",
    "\n",
    "## Calculate classification error rate\n",
    "yp_cls = [1 if yout >= 0 else 0 for yout in y_predict]   \n",
    "difference = np.abs(y_test - yp_cls)\n",
    "test_error_count = (difference == 1).sum()\n",
    "test_error_rate = test_error_count/len(y_test)\n",
    "print(test_error_rate)\n",
    "\n",
    "##--- Compute FPR and FNR at different thresholds ---##\n",
    "## separate the two classes of predicted data based on the ground truth y_test\n",
    "pos_idx = np.where(y_test == 1) # identify the indexing of positive-class in the test set\n",
    "neg_idx = np.where(y_test == 0) # identify the indexing of negative-class in the test set\n",
    "y_predict_for_PosSamples = y_predict[pos_idx] # prediction of the positive-class data\n",
    "y_predict_for_NegSamples = y_predict[neg_idx] # prediction of the negative-class data\n",
    "## use the shorter among the two arrays as threshold\n",
    "if ( len(y_predict_for_PosSamples) <= len(y_predict_for_NegSamples) ): \n",
    "    sorted = np.sort(y_predict_for_PosSamples) # sort in ascending order to be used as threshold\n",
    "else:\n",
    "    sorted = np.sort(y_predict_for_NegSamples) # sort in ascending order to be used as threshold\n",
    "FNR = []\n",
    "FPR = []  \n",
    "TPR = []  \n",
    "## Compute FNR, FPR, and TPR for each threshold\n",
    "for k in range(len(sorted)):\n",
    "    yp_cls_pos = np.abs([1 if yout >= sorted[k] else 0 for yout in y_predict_for_PosSamples])   \n",
    "    yp_cls_neg = np.abs([1 if yout >= sorted[k] else 0 for yout in y_predict_for_NegSamples]) \n",
    "    FNR += [(yp_cls_pos == 0).sum()/len(y_predict_for_PosSamples)]\n",
    "    FPR += [(yp_cls_neg == 1).sum()/len(y_predict_for_NegSamples)]\n",
    "    TPR += [1-(yp_cls_pos == 0).sum()/len(y_predict_for_PosSamples)]\n",
    "##--- Plot ROC and DET curves ---##\n",
    "plt.plot(FPR, FNR, '-', label = 'DET')\n",
    "plt.plot(FPR, TPR, '-', label = 'ROC')\n",
    "plt.xlabel('FPR') \n",
    "plt.ylabel('FNR/TPR')\n",
    "plt.legend(fontsize=15)\n",
    "##--- Comput AUC ---##\n",
    "ypos_array = [[1 if y_predict_for_PosSamples[j] >= y_predict_for_NegSamples[k] else 0\n",
    "               for j in range(len(y_predict_for_PosSamples))] for k in range(len(y_predict_for_NegSamples))]    \n",
    "AUC = np.sum(ypos_array)/(len(y_predict_for_PosSamples)*len(y_predict_for_NegSamples))\n",
    "print(AUC)\n",
    "\n",
    "ypos_array_1=[[0 for i in range(len(y_predict_for_PosSamples))] for j in range(len(y_predict_for_NegSamples))]\n",
    "\n",
    "for j in range(len(y_predict_for_PosSamples)) :\n",
    "    for k in range(len(y_predict_for_NegSamples)) :\n",
    "        if y_predict_for_PosSamples[j] >= y_predict_for_NegSamples[k] :\n",
    "            ypos_array_1[k][j]= 1\n",
    "        else :\n",
    "            ypos_array_1[k][j]= 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
